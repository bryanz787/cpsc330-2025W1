{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e57111-93ae-437f-976b-1176c074e402",
   "metadata": {},
   "source": [
    "# Appendix A: Lecture 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3272a754-cb97-471c-ba83-30df2be2025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(\"..\"), \"code\"))\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay  # Recommended method in sklearn 1.0\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from IPython.display import Image\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c019e4e-ed4b-43f2-a92a-a2e4f9ee485b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Optional) Search and score\n",
    "\n",
    "- Define a **scoring function** $f(S)$ that measures the quality of the set of features $S$. \n",
    "- Now **search** for the set of features $S$ with the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d92119-a406-425f-8330-4cf09b296ca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General idea of search and score methods \n",
    "\n",
    "- Example: Suppose you have three features: $A, B, C$\n",
    "    - Compute **score** for $S = \\{\\}$\n",
    "    - Compute **score** for $S = \\{A\\}$\n",
    "    - Compute **score** for $S= \\{B\\}$\n",
    "    - Compute **score** for $S = \\{C\\}$\n",
    "    - Compute **score** for $S = \\{A,B\\}$    \n",
    "    - Compute **score** for $S = \\{A,C\\}$\n",
    "    - Compute **score** for $S = \\{B,C\\}$\n",
    "    - Compute **score** for $S = \\{A,B,C\\}$    \n",
    "- Return $S$ with the best score.  \n",
    "- How many distinct combinations we have to try out? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1739fcbb-433b-4b19-b3bf-a047cc42e94f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Optional) Forward or backward selection \n",
    "\n",
    "- Also called wrapper methods\n",
    "- Shrink or grow feature set by removing or adding one feature at a time \n",
    "- Makes the decision based on whether adding/removing the feature improves the CV score or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844dd19-dd7f-4d2f-884f-24945c29dee7",
   "metadata": {},
   "source": [
    "![](../img/forward_selection.png)\n",
    "\n",
    "<!-- <img src='img/forward_selection.png' width=\"1000\" height=\"1000\" /> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a3c2f1-0ce4-4efc-a593-0380a2ab42b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# pipe_forward = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     SequentialFeatureSelector(LogisticRegression(max_iter=1000), \n",
    "#                               direction=\"forward\", \n",
    "#                               n_features_to_select='auto', \n",
    "#                               tol=None),\n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "# )\n",
    "# pd.DataFrame(\n",
    "#     cross_validate(pipe_forward, X_train, y_train, return_train_score=True)\n",
    "# ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c087852b-dc6f-42d2-b403-c3ea623d87cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# pipe_forward = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     SequentialFeatureSelector(\n",
    "#         LogisticRegression(max_iter=1000), \n",
    "#                            direction=\"backward\", \n",
    "#                            n_features_to_select=15),\n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "# )\n",
    "# pd.DataFrame(\n",
    "#     cross_validate(pipe_forward, X_train, y_train, return_train_score=True)\n",
    "# ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73b13c-0342-4ad8-bb89-260ab1eeaa96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other ways to search \n",
    "\n",
    "- Stochastic local search\n",
    "    - Inject randomness so that we can explore new parts of the search space\n",
    "    - Simulated annealing\n",
    "    - Genetic algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f81df-eefa-4b53-8b80-7e3e9423cecd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Warnings about feature selection \n",
    "\n",
    "- A feature's relevance is only defined in the context of other features.\n",
    "    - Adding/removing features can make features relevant/irrelevant.\n",
    "- If features can be predicted from other features, you cannot know which one to pick. \n",
    "- Relevance for features does not have a causal relationship. \n",
    "- Don't be overconfident. \n",
    "    - The methods we have seen probably do not discover the ground truth and how the world really works.\n",
    "    - They simply tell you which features help in predicting $y_i$ for the data you have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e596cc-0b85-4fd1-9c23-88e7c73a70ad",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e0367-1158-456f-9014-f6f3483fe009",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Optional) Problems with feature selection \n",
    "\n",
    "- The term 'relevance' is not clearly defined.\n",
    "- What all things can go wrong with feature selection?\n",
    "- Attribution: From CPSC 340. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2413fd-26d7-4c90-9b37-989b1b1d0819",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Is \"Relevance\" clearly defined?\n",
    "\n",
    "- Consider a supervised classification task of predicting whether someone has particular genetic variation (SNP)\n",
    "\n",
    "![](../img/sex_mom_dad.png)\n",
    "\n",
    "<!-- <img src='../img/sex_mom_dad.png' width=\"600\" height=\"600\" /> -->\n",
    "\n",
    "- True model: You almost have the same value as your biological mom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c49434-bfcf-43f5-a3b6-4b84249cffa1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- True model: You almost have the same value for SNP as your biological mom.\n",
    "    - (SNP = biological mom) with very high probability \n",
    "    - (SNP != biological mom) with very low probability \n",
    "    \n",
    "\n",
    "![](../img/SNP.png)\n",
    "\n",
    "<!-- <img src='../img/SNP.png' width=\"400\" height=\"400\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19cc13-18b8-4f76-8c6b-19a07d048ad1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- What if \"mom\" feature is repeated?\n",
    "- Should we pick both? Should we pick one of them because it predicts the other? \n",
    "- Dependence, collinearity for linear models\n",
    "    - If a feature can be predicted from the other, don't know which one to pick. \n",
    "\n",
    "![](../img/sex_mom_mom2_dad.png)\n",
    "\n",
    "<!-- <img src='../img/sex_mom_mom2_dad.png' width=\"600\" height=\"600\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ad2b6-f378-42a2-a331-644bfaab6270",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- What if we add (maternal) \"grandma\" feature?\n",
    "- Is it relevant? \n",
    "    - We can predict SNP accurately using this feature\n",
    "- Conditional independence\n",
    "    - But grandma is irrelevant given biological mom feature\n",
    "    - Relevant features may become irrelevant given other features\n",
    "\n",
    "![](../img/sex_mom_dad_grandma.png)\n",
    "<!-- <img src='../img/sex_mom_dad_grandma.png' width=\"600\" height=\"600\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0997342-dd7f-4cb5-be70-89fa63900a21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- What if we do not know biological mom feature and we just have grandma feature\n",
    "- It becomes relevant now. \n",
    "    - Without mom feature this is the best we can do. \n",
    "- General problem (\"taco Tuesday\" problem)\n",
    "    - Features can become relevant due to missing information \n",
    "\n",
    "![](../img/sex_dad_grandma.png)\n",
    "\n",
    "<!-- <img src='../img/sex_dad_grandma.png' width=\"600\" height=\"600\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfd985-0443-4151-9a6a-30fb013e61e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- Are there any relevant features now?\n",
    "- They may have some common maternal ancestor.   \n",
    "- What if mom likes dad because they share SNP? \n",
    "- General problem (Confounding)\n",
    "    - Hidden features can make irrelevant features relevant.\n",
    "\n",
    "![](../img/sex_dad.png)\n",
    "\n",
    "<!-- <img src='../img/sex_dad.png' width=\"600\" height=\"600\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb74fb-4cc0-4454-a0d4-2e10f37e65f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- Now what if we have \"sibling\" feature? \n",
    "- The feature is relevant in predicting SNP but not the cause of SNP. \n",
    "- General problem (non causality)\n",
    "    - the relevant feature may not be causal \n",
    "\n",
    "![](../img/sex_dad_sibling.png)\n",
    "\n",
    "<!-- <img src='../img/sex_dad_sibling.png' width=\"600\" height=\"600\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e48cab-042e-4f92-959f-af86e8e61d32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Is \"Relevance\" clearly defined?\n",
    "\n",
    "- What if you are given \"baby\" feature?\n",
    "- Now the sex feature becomes relevant. \n",
    "    - \"baby\" feature is relevant when sex == F\n",
    "    \n",
    "- General problem (context specific relevance)\n",
    "    - adding a feature can make an irrelevant feature relevant\n",
    "\n",
    "![](../img/sex_dad_baby.png)\n",
    "<!-- <img src='../img/sex_dad_baby.png' width=\"600\" height=\"600\"/> -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
